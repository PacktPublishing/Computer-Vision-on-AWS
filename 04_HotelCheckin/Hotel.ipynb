{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Rekognition Face API\n",
    "\n",
    "This notebook contains example snippets for interacting with Face API."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, confirm that the `boto3` module is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in c:\\tools\\python3.8\\lib\\site-packages (1.17.84)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.84 in c:\\tools\\python3.8\\lib\\site-packages (from boto3) (1.20.84)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\tools\\python3.8\\lib\\site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in c:\\tools\\python3.8\\lib\\site-packages (from boto3) (0.4.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\tools\\python3.8\\lib\\site-packages (from botocore<1.21.0,>=1.20.84->boto3) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\tools\\python3.8\\lib\\site-packages (from botocore<1.21.0,>=1.20.84->boto3) (1.26.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\tools\\python3.8\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.84->boto3) (1.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.0; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\tools\\python3.8\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install boto3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the global settings for running this notebook.\n",
    "\n",
    "1. Set the `bucket_name` to an Amazon S3 bucket within your AWS account.\n",
    "1. Set the `region_name` to the AWS Region containing your bucket\n",
    "1. Create the `rekognition` client for the same region as the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "bucket_name = 'ch04-hotel-use2'\n",
    "region_name = 'us-east-2'\n",
    "image_name = 'images/Nate-Bachmeier.png'\n",
    "rekognition = boto3.client('rekognition', region_name=region_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoke the `DetectFaces` API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = rekognition.detect_faces(\n",
    "    Attributes=['ALL'],\n",
    "    Image={\n",
    "     'S3Object':{\n",
    "        'Bucket': bucket_name,\n",
    "        'Name': image_name\n",
    "      }\n",
    "    })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create the `print_faces` function for pretty printing the `faces` response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person 1 is Male(100.00%) around 31 age and CALM(96.24%) state.\n"
     ]
    }
   ],
   "source": [
    "def print_faces(faces):\n",
    "    counter=0\n",
    "    for face in faces['FaceDetails']:\n",
    "        counter+=1\n",
    "        age_range = face['AgeRange']\n",
    "        gender = face['Gender']\n",
    "        emotions = face['Emotions']\n",
    "        \n",
    "        age = (age_range['High'] + age_range['Low'])/2\n",
    "        emotions.sort(key=lambda x: x['Confidence'], reverse=True)\n",
    "        top_emotion = emotions[0]\n",
    "\n",
    "        print('Person %d is %s(%2.2f%%) around %d age and %s(%2.2f%%) state.' % (\n",
    "            counter,\n",
    "            gender['Value'],\n",
    "            gender['Confidence'],\n",
    "            age,\n",
    "            top_emotion['Type'],\n",
    "            top_emotion['Confidence']\n",
    "        ))\n",
    "\n",
    "print_faces(faces)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can build policies that `check_faces` is valid and meets our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid face detected!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def has_only_one_face(faces):\n",
    "    if len(faces['FaceDetails']) == 1:\n",
    "       return True\n",
    "    return False\n",
    "\n",
    "def is_facing_forward(face):\n",
    "    for dimension in ['Pitch','Roll','Yaw']:\n",
    "        value = face['Pose'][dimension]\n",
    "        if not (-45 < value and value < 45):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def has_sunglasses(face):\n",
    "    sunglasses = face['Sunglasses']['Value']\n",
    "    return sunglasses\n",
    "\n",
    "def is_well_lit(face):\n",
    "    if face['Quality']['Brightness'] < 25:\n",
    "        return False    \n",
    "    return True\n",
    "\n",
    "def check_faces(faces):\n",
    "    if not has_only_one_face(faces):\n",
    "        print('Incorrect face count.')\n",
    "        return False\n",
    "\n",
    "    user_face = faces['FaceDetails'][0]\n",
    "    if not is_facing_forward(user_face):\n",
    "        print('Customer not facing forward')\n",
    "        return False\n",
    "\n",
    "    if has_sunglasses(user_face):\n",
    "        print('Please take off sunglasses.')\n",
    "        return False\n",
    "\n",
    "    if not is_well_lit(user_face):\n",
    "        print('The image is blurry')\n",
    "        return False\n",
    "\n",
    "    print(\"Valid face detected!\")\n",
    "    return True\n",
    "\n",
    "check_faces(faces)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's use the `Index` API to persist FaceMetadata into the `HotelCollection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_id=\"HotelCollection\"\n",
    "image_set = {\n",
    "    'nbachmei': 'images/Nate-Bachmeier.png',\n",
    "    'lemull': 'images/Lauren-Mullennex.jpg'\n",
    "}\n",
    "\n",
    "for (externalImageId, object_name) in image_set.items():\n",
    "    rekognition.index_faces(\n",
    "        CollectionId = collection_id,\n",
    "        ExternalImageId=externalImageId,\n",
    "        Image={\n",
    "            'S3Object':{\n",
    "                'Bucket': bucket_name,\n",
    "                'Name': object_name\n",
    "            }\n",
    "        })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `SearchFacesByImage` API to find the indexed face using a different image of that person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_image = 'images/SearchFacesByImageExample.jpg'\n",
    "\n",
    "response = rekognition.search_faces_by_image(\n",
    "    CollectionId=collection_id,\n",
    "    Image={\n",
    "        'S3Object':{\n",
    "            'Bucket': bucket_name,\n",
    "            'Name': search_image\n",
    "        }\n",
    "    })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pretty print the response and confirm the `ExternalImageId` is Nate..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image is nbachmei (100.00% confidence)\n"
     ]
    }
   ],
   "source": [
    "def print_search_results(search_response):\n",
    "    for match in search_response['FaceMatches']:\n",
    "        externalImageId = match['Face']['ExternalImageId']\n",
    "        confidence = match['Face']['Confidence']\n",
    "\n",
    "        print('This image is %s (%2.2f%% confidence)' % (\n",
    "            externalImageId,\n",
    "            confidence\n",
    "        ))\n",
    "\n",
    "print_search_results(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This snippet creates the Amazon Textract client and invokes the `AnalyzeId` API. You can use this action to parse government identity cards like drivers licensing and passport cards. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "textract = boto3.client('textract', region_name=region_name)\n",
    "passport_card = 'images/passport_card.jpeg'\n",
    "\n",
    "response = textract.analyze_id(\n",
    "    DocumentPages=[\n",
    "        {\n",
    "            \"S3Object\":{\n",
    "                \"Bucket\": bucket_name,\n",
    "                \"Name\": passport_card\n",
    "            }\n",
    "        }\n",
    "    ])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pretty print the `response` from the `AnalyzeId` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"FIRST_NAME\": \"HAPPY\",\n",
      "  \"LAST_NAME\": \"TRAVELER\",\n",
      "  \"MIDDLE_NAME\": \"\",\n",
      "  \"SUFFIX\": \"\",\n",
      "  \"CITY_IN_ADDRESS\": \"\",\n",
      "  \"ZIP_CODE_IN_ADDRESS\": \"\",\n",
      "  \"STATE_IN_ADDRESS\": \"\",\n",
      "  \"STATE_NAME\": \"\",\n",
      "  \"DOCUMENT_NUMBER\": \"C03005988\",\n",
      "  \"EXPIRATION_DATE\": \"29 NOV 2019\",\n",
      "  \"DATE_OF_BIRTH\": \"1 JAN 1981\",\n",
      "  \"DATE_OF_ISSUE\": \"30 NOV 2009\",\n",
      "  \"ID_TYPE\": \"DRIVER LICENSE FRONT\",\n",
      "  \"ENDORSEMENTS\": \"\",\n",
      "  \"VETERAN\": \"\",\n",
      "  \"RESTRICTIONS\": \"\",\n",
      "  \"CLASS\": \"\",\n",
      "  \"ADDRESS\": \"\",\n",
      "  \"COUNTY\": \"\",\n",
      "  \"PLACE_OF_BIRTH\": \"NEW YORK U.S.A.\",\n",
      "  \"MRZ_CODE\": \"\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from json import dumps\n",
    "\n",
    "fields = {}\n",
    "for document in response['IdentityDocuments']:    \n",
    "    for field in document['IdentityDocumentFields']:\n",
    "        key = field['Type']['Text']\n",
    "        value = field['ValueDetection']['Text']    \n",
    "        fields[key] = value\n",
    "\n",
    "print(dumps(fields,indent=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `CompareFaces` to determine the similar between two images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/nbachmei-passport.jpg face with 98.77% similarity \n",
      "images/passport_card.jpeg has 1 unmatched faces\n"
     ]
    }
   ],
   "source": [
    "nbachmei_image = \"images/Nate-Bachmeier.png\"\n",
    "match_passport = \"images/nbachmei-passport.jpg\"\n",
    "nonmatch_passport = \"images/passport_card.jpeg\"\n",
    "\n",
    "def compare_faces(passport_card):\n",
    "    comparison_match = rekognition.compare_faces(\n",
    "        SourceImage={\n",
    "            \"S3Object\":{\n",
    "                \"Bucket\": bucket_name,\n",
    "                \"Name\": nbachmei_image\n",
    "            }\n",
    "        },\n",
    "        TargetImage={\n",
    "            \"S3Object\":{\n",
    "                \"Bucket\": bucket_name,\n",
    "                \"Name\": passport_card\n",
    "            }\n",
    "        })\n",
    "\n",
    "    if len(comparison_match['FaceMatches'])  > 0:\n",
    "        for face in comparison_match['FaceMatches']:\n",
    "            similarity = face['Similarity']\n",
    "            print('%s face with %2.2f%% similarity ' % (\n",
    "                passport_card, \n",
    "                similarity))\n",
    "    else:\n",
    "        print(\"%s has %d unmatched faces\" % (\n",
    "            passport_card,\n",
    "            len(comparison_match['UnmatchedFaces']))\n",
    "        )\n",
    "\n",
    "compare_faces(match_passport)\n",
    "compare_faces(nonmatch_passport)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "5628284b50e4b6c9011efabc1680bd979bbb5388d9d40dd889329c704489cf65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
